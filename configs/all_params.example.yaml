train:
  train_data: data/train.bin
  valid_data: data/valid.bin
  data_dtype: uint16
  out_dir: runs/exp_train
  resume_from: null

  vocab_size: 10000
  context_length: 256
  d_model: 512
  d_ff: null
  num_layers: 4
  num_heads: 16
  rope_theta: 10000.0

  optimizer: adamw
  learning_rate: 0.0003
  min_learning_rate: 0.00003
  warmup_iters: 200
  cosine_cycle_iters: null
  beta1: 0.9
  beta2: 0.95
  eps: 1.0e-8
  weight_decay: 0.1
  grad_clip: 1.0

  batch_size: 32
  max_steps: 5000
  log_interval: 10
  eval_interval: 200
  eval_iters: 50
  ckpt_interval: 500

  no_rmsnorm: false
  norm_style: pre
  no_rope: false
  ffn_type: swiglu

  device: auto
  seed: 1337
  matmul_precision: null
  compile: false
  compile_backend: null

  wandb_project: ""
  wandb_name: null

train-from-text:
  train_text: data/TinyStoriesV2-GPT4-train.txt
  valid_text: data/TinyStoriesV2-GPT4-valid.txt
  special_tokens: ["<|endoftext|>"]
  data_dtype: uint16
  out_dir: runs/exp_tft
  overwrite: false
  resume_from: null
  encode_workers: 8
  encode_backend: pool
  encode_slot_tokens: 0
  encode_num_slots: 0

  vocab_size: 10000
  context_length: 256
  d_model: 512
  d_ff: null
  num_layers: 4
  num_heads: 16
  rope_theta: 10000.0

  optimizer: adamw
  learning_rate: 0.0003
  min_learning_rate: 0.00003
  warmup_iters: 200
  cosine_cycle_iters: null
  beta1: 0.9
  beta2: 0.95
  eps: 1.0e-8
  weight_decay: 0.1
  grad_clip: 1.0

  batch_size: 32
  max_steps: 5000
  log_interval: 10
  eval_interval: 200
  eval_iters: 50
  ckpt_interval: 500

  no_rmsnorm: false
  norm_style: pre
  no_rope: false
  ffn_type: swiglu

  device: auto
  seed: 1337
  matmul_precision: null
  compile: false
  compile_backend: null

  wandb_project: ""
  wandb_name: null

generate:
  checkpoint: runs/exp_train/checkpoint_final.pt
  vocab_path: runs/exp_tft/vocab.json
  merges_path: runs/exp_tft/merges.txt
  special_tokens: ["<|endoftext|>"]

  context_length: 256
  d_model: 512
  d_ff: null
  num_layers: 4
  num_heads: 16
  rope_theta: 10000.0

  no_rmsnorm: false
  norm_style: pre
  no_rope: false
  ffn_type: swiglu

  prompt: "Once upon a time"
  max_new_tokens: 256
  temperature: 1.0
  top_p: 0.9
  top_k: 0
  repetition_penalty: 1.0
  stop_strings: []
  eos_token: "<|endoftext|>"

  seed: 1337
  device: auto
  matmul_precision: null
  compile: false
  compile_backend: null
